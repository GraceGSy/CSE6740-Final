{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explain the performance and classification results of each model, we designed an interactive visual analytics system that explains the feature space of the data set, as well as the outcomes of each model.\n",
    "\n",
    "We begin by doing some simple preprocessing of the data features, using UMAP to perform dimensionality reduction such that the data can be easily visualized on a 2D scatterplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the model predictions for each data sample in our testing split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "df_original = pd.read_csv('../public/all-models/lin_reg-test-original.csv')\n",
    "\n",
    "original_cols = df_original.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also use our models to classify some of our own music. These samples are unlabeled music pieces that were released more recently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our models on some unlabeled data\n",
    "df_test = pd.read_csv('../public/test-data-prediction-results.csv')\n",
    "\n",
    "df_test['genre'] = pd.Series([-1 for x in range(len(df_test.index))])\n",
    "\n",
    "df_test = df_test.rename(columns={'linear_regression': 'lin_reg_predicted',\n",
    "                                  'logistic_regression': 'log_reg_predicted',\n",
    "                                  'random_forest': 'rf_predicted',\n",
    "                                  'svm': 'svm_clf_predicted',\n",
    "                                  'multi-layer_perceptron': 'mlp_predicted',\n",
    "                                  'gaussian_process': 'gpc_predicted',\n",
    "                                  'gaussian_naive_bayes': 'gnb_predicted',\n",
    "                                  'knn': 'knn_predicted',\n",
    "                                  'gaussian_mixture_model': 'gmm_predicted'})\n",
    "\n",
    "df_test_cols = df_test.columns.values.tolist()\n",
    "\n",
    "# Get features only of test data\n",
    "\n",
    "df_test_features = df_test.drop(columns=['lin_reg_predicted', 'log_reg_predicted', 'rf_predicted',\n",
    "                                         'svm_clf_predicted', 'mlp_predicted', 'gpc_predicted',\n",
    "                                         'gnb_predicted', 'knn_predicted','gmm_predicted',\n",
    "                                         'index', 'genre', 'filepath', 'filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE UMAP\n",
    "df_features = df_original.drop(columns=[\"index\", \"genre\", \"filepath\", \"filename\"])\n",
    "\n",
    "# Concat original and test data\n",
    "df_joined = pd.concat([df_features, df_test_features])\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "scaled_data = StandardScaler().fit_transform(df_joined)\n",
    "embedding = reducer.fit_transform(scaled_data)\n",
    "coords = pd.DataFrame(embedding)\n",
    "\n",
    "# Original coords\n",
    "original_coords = coords.iloc[:300,:]\n",
    "\n",
    "# Test coords\n",
    "test_coords = coords.iloc[300:,:].reset_index(drop=True)\n",
    "\n",
    "# Get new column names\n",
    "new_cols = original_cols + ['x', 'y']\n",
    "new_test_cols = df_test_cols + ['x', 'y']\n",
    "\n",
    "# Add coords to test data\n",
    "df_test_final = pd.concat([df_test, test_coords], axis=1)\n",
    "df_test_final.columns =  new_test_cols\n",
    "\n",
    "# Add coords and predictions to original data\n",
    "df_original_final = pd.concat([df_original, original_coords], axis=1)\n",
    "\n",
    "# Get predicted for each model\n",
    "models = ['gmm', 'gnb', 'gpc', 'knn', 'lin_reg', 'log_reg', 'mlp', 'rf', 'svm_clf']\n",
    "\n",
    "for m in models:\n",
    "    df_predict = pd.read_csv('../public/all-models/' + m + '-test-predict.csv')\n",
    "    predicted = df_predict[\"genre\"]\n",
    "    \n",
    "    new_cols = new_cols + [m + '_predicted']\n",
    "    \n",
    "    df_original_final = pd.concat([df_original_final, predicted], axis=1)\n",
    "\n",
    "df_original_final.columns = new_cols\n",
    "\n",
    "# Concat original and test data\n",
    "df_final = pd.concat([df_test_final, df_original_final]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_json(\"./all-models-with-coords.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a visual analytics tool that explores the feature space of the data set and classification results of the different models. We will now demonstrate the visualization by walking you through some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import widget\n",
    "from ReactWidget import Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReactWidget.test.Test"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_json(\"../public/all-models-with-coords.json\")\n",
    "\n",
    "result2 = df2.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f8a59c2a8a4273b2a463c6907a47b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test(component='Test', props={'data': [{'index': 0, 'filepath': 'data/test-dataset/Song-8.wav', 'filename': 'Sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the basic visualization interface\n",
    "# Different models can be selected using the drop down\n",
    "# Each song is plotted on the 2D scatterplot\n",
    "# Its labeled genre is the fill color\n",
    "# While the predicted genre is the stroke color on the outside\n",
    "# We can zoom in to see the details\n",
    "\n",
    "Test(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
